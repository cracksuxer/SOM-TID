{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# # Import from scikit-learn\n",
    "# # sudo pip install scikit-learn\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Import from NeuPy\n",
    "from neupy import algorithms, utils, init\n",
    "\n",
    "# Import from datetime\n",
    "from datetime import datetime\n",
    "\n",
    "# Import prettier output\n",
    "from rich import print\n",
    "from rich.console import Console\n",
    "from rich.traceback import install\n",
    "install(show_locals=True)\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">n_samples: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">284807</span>, n_features: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "n_samples: \u001b[1;36m284807\u001b[0m, n_features: \u001b[1;36m31\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cc_df = pd.read_csv('./data/creditcard.csv')\n",
    "\n",
    "(n_samples, n_features) = cc_df.shape\n",
    "\n",
    "print(f\"n_samples: {n_samples}, n_features: {n_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corr = cc_df.corr()\n",
    "\n",
    "for i in range(len(cc_df.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(data_corr.iloc[i, j]) > 0.88:\n",
    "            print(data_corr.columns[i], data_corr.columns[j], data_corr.iloc[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback import print_tb\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "TARGET = cc_df['Class']\n",
    "FEATURES = cc_df.drop(['Class'], axis=1)\n",
    "\n",
    "features_train, features_aux, target_train, target_aux = train_test_split(FEATURES, TARGET, test_size=0.5, random_state=42)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_aux, target_aux, test_size=0.5, random_state=42)\n",
    "\n",
    "# Balance trainning data with SMOTETomek\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "features_train, target_train = smote_tomek.fit_resample(features_train, target_train)\n",
    "\n",
    "print(f'features_train: {features_train.shape}')\n",
    "print(f'features_valid: {features_valid.shape}')\n",
    "print(f'features_test: {features_test.shape}')\n",
    "print(f'target_train: {target_train.shape}')\n",
    "print(f'target_valid: {target_valid.shape}')\n",
    "print(f'target_test: {target_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Learning 2<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x20</span> SOM with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span> maximum number of iterations and <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Learning 2\u001b[1;36m0x20\u001b[0m SOM with \u001b[1;36m25\u001b[0m maximum number of iterations and \u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Main information\n",
      "\n",
      "[ALGORITHM] SOFM\n",
      "\n",
      "[OPTION] verbose = True\n",
      "[OPTION] epoch_end_signal = None\n",
      "[OPTION] show_epoch = 1\n",
      "[OPTION] shuffle_data = False\n",
      "[OPTION] step = 0.5\n",
      "[OPTION] train_end_signal = None\n",
      "[OPTION] n_inputs = 30\n",
      "[OPTION] distance = euclid\n",
      "[OPTION] features_grid = [20, 20]\n",
      "[OPTION] grid_type = rect\n",
      "[OPTION] learning_radius = 5\n",
      "[OPTION] n_outputs = None\n",
      "[OPTION] reduce_radius_after = 5\n",
      "[OPTION] reduce_std_after = 20\n",
      "[OPTION] reduce_step_after = 20\n",
      "[OPTION] std = 1.0\n",
      "[OPTION] weight = Normal(mean=0, std=0.01)\n",
      "\n",
      "\n",
      "Start training\n",
      "\n",
      "[TRAINING DATA] shapes: (282854, 30)\n",
      "[TRAINING] Total epochs: 25\n",
      "\n",
      "---------------------------------------------------------\n",
      "|    Epoch    |  Train err  |  Valid err  |    Time     |\n",
      "---------------------------------------------------------\n",
      "|           1 |      423.45 |           - |       01:08 |\n"
     ]
    }
   ],
   "source": [
    "# Modeling SOM\n",
    "# ------------\n",
    "max_iter_som = 25\n",
    "grid_height = 20\n",
    "grid_width = 20\n",
    "distance = 'euclid'\n",
    "learning_radius = 5\n",
    "step = 0.5\n",
    "reduce_step_after = max_iter_som - 5\n",
    "std = 1.0\n",
    "reduce_std_after = max_iter_som - 5\n",
    "weight = init.Normal()\n",
    "\n",
    "print(\"Learning %dx%d SOM with %d maximum number of iterations and ...\" % (grid_height, grid_width, max_iter_som))\n",
    "\n",
    "now = datetime.now()\n",
    "# Random generator seed for NeuPy\n",
    "# utils.reproducible(0)\n",
    "\n",
    "sofm = algorithms.SOFM(\n",
    "    n_inputs = features_train.shape[1],\n",
    "    features_grid = (grid_height, grid_width),\n",
    "    distance = distance,\n",
    "    weight = weight,\n",
    "    learning_radius = learning_radius,\n",
    "    reduce_radius_after = max_iter_som // learning_radius,  # 0 radius at end\n",
    "    step = step,\n",
    "    reduce_step_after = reduce_step_after,\n",
    "    std = std,\n",
    "    reduce_std_after = reduce_std_after,\n",
    "    shuffle_data = False,\n",
    "    verbose = True,\n",
    ")\n",
    "\n",
    "sofm.train(features_train, epochs=max_iter_som)\n",
    "sofm_output_train = sofm.predict(features_train)\n",
    "sofm_output_valid = sofm.predict(features_valid)\n",
    "print(\"Number of seconds for training: %d\" % (datetime.now() - now).total_seconds())\n",
    "\n",
    "# Show results\n",
    "print(\"Visualizing the Mean Absolute Error Trajectory\")\n",
    "# plt.plot(range(1, len(sofm.errors.train)+1), sofm.errors.train)\n",
    "plt.plot(range(1, len(sofm.errors)+1), sofm.errors)\n",
    "plt.xlabel('number of iterations')\n",
    "plt.ylabel('MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototypes visualization\n",
    "# ------------\n",
    "# have a look at the grid\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "def plot_prototypes_grid(grid_height, grid_width, prototypes, labels=[]):\n",
    "    \"\"\"\n",
    "    Visualization prototypes of SOM grid and labels\n",
    "    \"\"\"\n",
    "    print(\"Building visualization of prototypes grid ...\")\n",
    "    grid = gridspec.GridSpec(grid_height, grid_width)\n",
    "    grid.update(wspace=0, hspace=0)\n",
    "    for row_id in range(grid_height):\n",
    "        print(\"Progress: {:.2%}\".format(row_id / grid_height))\n",
    "        for col_id in range(grid_width):\n",
    "            index = row_id * grid_width + col_id\n",
    "            prototype = prototypes[index]\n",
    "            _ = plt.subplot(grid[index])\n",
    "            _ = plt.bar(range(len(prototype)), prototype)\n",
    "            if len(labels):\n",
    "                _ = plt.text(0, 0, labels[index], color='r', fontsize=8)\n",
    "            _ = plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_prototypes_grid(grid_height, grid_width, sofm.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling Perceptron\n",
    "# ------------\n",
    "# Perceptron use de SOM output (grid array of 0 except winning output).\n",
    "# That is, Counterpropagation Network (CPN)\n",
    "max_iter_per = 30\n",
    "\n",
    "print(\"Learning a Perceptron with %d maximum number of iterations and ...\" % max_iter_per)\n",
    "\n",
    "per = Perceptron(max_iter=max_iter_per, shuffle=False, verbose=True)\n",
    "per.fit(sofm_output_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intitial results\n",
    "# ------------\n",
    "print(\"Printing initial results\")\n",
    "\n",
    "predict_train = per.predict(sofm_output_train)\n",
    "predict_valid = per.predict(sofm_output_valid)\n",
    "\n",
    "print(\"Train accuracy: %.3f%%\" % (accuracy_score(target_train, predict_train) * 100))\n",
    "print(\"Valid accuracy: %.3f%%\" % (accuracy_score(target_valid, predict_valid) * 100))\n",
    "\n",
    "print(\"Train confusion matrix:\")\n",
    "print(confusion_matrix(target_train, predict_train))\n",
    "print(\"Valid confusion matrix:\")\n",
    "print(confusion_matrix(target_valid, predict_valid))\n",
    "\n",
    "print(\"Train classification report:\")\n",
    "print(classification_report(target_train, predict_train))\n",
    "print(\"Valid classification report:\")\n",
    "print(classification_report(target_valid, predict_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels visualization\n",
    "# ------------\n",
    "sofm_output_labels = np.zeros((grid_height * grid_width, grid_height * grid_width), dtype=int)\n",
    "for i in range(grid_height * grid_width):\n",
    "    sofm_output_labels[i][i] = 1\n",
    "predict_labels = per.predict(sofm_output_labels)\n",
    "\n",
    "plot_prototypes_grid(grid_height, grid_width, sofm.weight, predict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Architecture optimization\n",
    "# ------------\n",
    "print(\"Architecture optimization\")\n",
    "\n",
    "# Test SOM with differents number of grid units and several repetitions\n",
    "tests_grid_side = [5, 10, 15, 20, 25, 30, 35]\n",
    "n_reps = 5\n",
    "\n",
    "now = datetime.now()\n",
    "best_sofm = []\n",
    "best_per = []\n",
    "best_acc = 0.0\n",
    "accs_train = []\n",
    "accs_valid = []\n",
    "for grid_side in tests_grid_side:\n",
    "    max_acc_train = max_acc_valid = 0.0\n",
    "    for random_state in range(n_reps):\n",
    "        # utils.reproducible(random_state)\n",
    "        sofm = algorithms.SOFM(\n",
    "            n_inputs = features_train.shape[1],\n",
    "            features_grid = (grid_side, grid_side), \n",
    "            distance = distance, \n",
    "            weight = weight, \n",
    "            learning_radius = learning_radius, \n",
    "            reduce_radius_after = max_iter_som // learning_radius, \n",
    "            step = step, \n",
    "            reduce_step_after = reduce_step_after, \n",
    "            std = std, \n",
    "            reduce_std_after = reduce_std_after, \n",
    "            shuffle_data = False, \n",
    "            verbose = False\n",
    "        )\n",
    "        sofm.train(features_train, epochs=max_iter_som)\n",
    "        sofm_output_train = sofm.predict(features_train)\n",
    "        sofm_output_valid = sofm.predict(features_valid)\n",
    "        per = Perceptron(max_iter=max_iter_per, shuffle=False, verbose=False)\n",
    "        _ = per.fit(sofm_output_train, target_train)\n",
    "        acc_train = accuracy_score(target_train, per.predict(sofm_output_train))\n",
    "        acc_valid = accuracy_score(target_valid,per.predict(sofm_output_valid))\n",
    "        print(\"Seed = %d, train acc = %.8f, valid acc = %.8f\" % (random_state, acc_train, acc_valid))\n",
    "        if (max_acc_valid < acc_valid):\n",
    "            max_acc_valid = acc_valid\n",
    "            max_acc_train = acc_train\n",
    "            if (acc_valid > best_acc):\n",
    "                best_acc = acc_valid\n",
    "                best_per = per\n",
    "                best_sofm = sofm\n",
    "    accs_train.append(max_acc_train)\n",
    "    accs_valid.append(max_acc_valid)\n",
    "    print(\"Grid size = %ix%i, train acc = %.8f, max valid acc = %.8f\" % (grid_side, grid_side, max_acc_train, max_acc_valid))\n",
    "\n",
    "print(\"Number of seconds for training: %d\" % (datetime.now() - now).total_seconds())\n",
    "print(\"Best CPN valid accuracy: %.8f%%\" % (best_acc * 100))\n",
    "print(\"Best SOM: \", best_sofm)\n",
    "print(\"Best Perceptron: \", best_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results\n",
    "width = 2\n",
    "plt.bar(np.array(tests_grid_side) - width, 100 *(1- np.array(accs_train)), color='g', width=width, label='Train error')\n",
    "plt.bar(np.array(tests_grid_side), 100 *(1- np.array(accs_valid)), width=width, label='Min valid error')\n",
    "plt.xlabel('grid side')\n",
    "plt.ylabel('error (%)')\n",
    "plt.xticks(np.array(tests_grid_side), tests_grid_side)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final results of best CPN\n",
    "# ------------\n",
    "print(\"Printing final results\")\n",
    "\n",
    "sofm_output_train = best_sofm.predict(features_train)\n",
    "sofm_output_valid = best_sofm.predict(features_valid)\n",
    "sofm_output_test = best_sofm.predict(features_test)\n",
    "predict_train = best_per.predict(sofm_output_train)\n",
    "predict_valid = best_per.predict(sofm_output_valid)\n",
    "predict_test = best_per.predict(sofm_output_test)\n",
    "\n",
    "print(\"Train accuracy: %.3f%%\" % (accuracy_score(target_train, predict_train) * 100))\n",
    "print(\"Valid accuracy: %.3f%%\" % (accuracy_score(target_valid, predict_valid) * 100))\n",
    "print(\"Test accuracy: %.3f%%\" % (accuracy_score(target_test, predict_test) * 100))\n",
    "\n",
    "print(\"Train confusion matrix:\")\n",
    "print(confusion_matrix(target_train, predict_train))\n",
    "print(\"Valid confusion matrix:\")\n",
    "print(confusion_matrix(target_valid, predict_valid))\n",
    "print(\"Test confusion matrix:\")\n",
    "print(confusion_matrix(target_test, predict_test))\n",
    "\n",
    "print(\"Train classification report:\")\n",
    "print(classification_report(target_train, predict_train))\n",
    "print(\"Valid classification report:\")\n",
    "print(classification_report(target_valid, predict_valid))\n",
    "print(\"Test classification report:\")\n",
    "print(classification_report(target_test, predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves of test set\n",
    "per_probs = best_per.decision_function(sofm_output_test)\n",
    "classes  = np.unique(target_train)\n",
    "per_auc = []\n",
    "per_fpr = []\n",
    "per_tpr = []\n",
    "for cla in classes:\n",
    "   per_auc.append(roc_auc_score(target_test==cla, per_probs[:,cla]))\n",
    "   fpr, tpr, _ = roc_curve(target_test==cla, per_probs[:,cla])\n",
    "   per_fpr.append(fpr)\n",
    "   per_tpr.append(tpr)\n",
    "\n",
    "print(\"Printing ROC curves of test set\")\n",
    "# plot the roc curve for the model\n",
    "for cla in classes:\n",
    "   # plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "   _ = plt.plot(per_fpr[cla], per_tpr[cla], marker='.', label='Class %d (AUC: %.5f)' % (cla, per_auc[cla]))\n",
    "\n",
    "# axis labels\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show grid prototypes and labels\n",
    "(grid_height, grid_width) = best_sofm.features_grid\n",
    "sofm_output_labels = np.zeros((grid_height * grid_width, grid_height * grid_width), dtype=int)\n",
    "for i in range(grid_height * grid_width):\n",
    "    sofm_output_labels[i][i] = 1\n",
    "predict_labels = best_per.predict(sofm_output_labels)\n",
    "\n",
    "plot_prototypes_grid(grid_height, grid_width, best_sofm.weight, predict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show errors on real data\n",
    "indxs = np.where(predict_test == target_test)[0]\n",
    "indxs_err = indxs[(np.where(predict_test[(indxs)] != target_test[(indxs)]))[0]]\n",
    "preds_err = predict_test[(indxs_err)]\n",
    "\n",
    "count = [0, 0]\n",
    "\n",
    "for idx in indxs_err:\n",
    "    pred = predict_test[idx]\n",
    "    real = target_test.iloc[idx]\n",
    "    count[pred] += 1\n",
    "    print(\"Fila: %d Predicción: %d Real: %d\" % (idx, pred, real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "images_and_labels = list(zip(features_test.iloc[indxs_err].values.reshape((len(indxs_err), 8, 8)), target_test.iloc[indxs_err], preds_err))\n",
    "for ax, (image, label1, label2) in zip(np.concatenate(axes), images_and_labels):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('real:%i pred:%i' % (label1, label2))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf496632d6691adb1493289bd533842c7a72f473ba59ea0748ad55b1a1aa8af6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
